# JVM Profiling Guide for PerlOnJava

This guide documents how to profile and analyze performance issues in PerlOnJava.

## Table of Contents

1. [Basic Timing Measurements](#basic-timing-measurements)
2. [JVM Profiling Flags](#jvm-profiling-flags)
3. [Using JPERL_OPTS](#using-jperl_opts)
4. [Analysis Techniques](#analysis-techniques)
5. [Case Study: EVAL_USE_INTERPRETER Performance](#case-study)
6. [External Profiling Tools](#external-profiling-tools)

---

## Basic Timing Measurements

### Simple Perl-Level Timing

Create a test script to measure performance at the Perl level:

```perl
# /tmp/profile_test.pl
for my $x (1..100_000) {
    eval " \$var$x++"
}
print "$var1000\n";
```

Time it with bash `time`:

```bash
# Pure interpreter mode
time ./jperl --interpreter /tmp/profile_test.pl

# Compiled mode with interpreter eval
time JPERL_EVAL_USE_INTERPRETER=1 ./jperl /tmp/profile_test.pl

# Standard compiled mode
time ./jperl /tmp/profile_test.pl
```

The `time` command shows:
- **user**: CPU time spent in user mode
- **system**: CPU time spent in kernel mode
- **total**: Wall clock time (includes parallelization)

### Command-line One-liners

```bash
# Test specific iterations
time ./jperl -e 'for my $x (1..1_000_000) { eval "\$var$x++" }'

# Compare different modes
time ./jperl --interpreter -e 'for (1..100_000) { $x++ }'
time ./jperl -e 'for (1..100_000) { $x++ }'
```

---

## JVM Profiling Flags

The JVM provides many diagnostic flags for performance analysis. Use them via the `JPERL_OPTS` environment variable.

### PrintCompilation - See What JIT Compiles

```bash
JPERL_OPTS="-XX:+PrintCompilation" ./jperl script.pl
```

Output format:
```
   225   1       3       java.lang.String::hashCode (49 bytes)
   ^time ^id    ^tier   ^method (size)
```

Tiers:
- 0: Interpreter
- 1-3: C1 compiler (client)
- 4: C2 compiler (server, most optimized)

### PrintInlining - See Inlining Decisions

```bash
JPERL_OPTS="-XX:+UnlockDiagnosticVMOptions -XX:+PrintInlining" ./jperl script.pl 2>&1 | grep "evalString"
```

Shows which methods the JIT inlines (or fails to inline):
```
@ 75  org.perlonjava.runtime.RuntimeCode::evalStringHelper (421 bytes)  failed to inline: callee is too large
@ 12  org.perlonjava.interpreter.BytecodeCompiler::compile (181 bytes)  inline
```

Common reasons for failed inlining:
- "callee is too large" - method exceeds inlining threshold (default 325 bytes for hot methods)
- "already compiled into a big method" - would make caller too large
- "don't inline Throwable.fillInStackTrace" - exception handling
- "recursive inlining is too deep" - recursion depth limit

### LogCompilation - Detailed JIT Log

```bash
JPERL_OPTS="-XX:+UnlockDiagnosticVMOptions -XX:+LogCompilation -XX:LogFile=/tmp/jit.log" ./jperl script.pl
```

Generates XML log with:
- Compilation decisions
- Inlining tree
- Optimization attempts
- Deoptimizations

Analyze with JITWatch: https://github.com/AdoptOpenJDK/jitwatch

### PrintGC - Garbage Collection

```bash
JPERL_OPTS="-Xlog:gc*" ./jperl script.pl
```

Shows GC pauses and memory pressure. Useful for:
- Detecting excessive allocations
- Understanding pause times
- Tuning heap size

### PrintAssembly - Native Code

```bash
# Requires hsdis library installed
JPERL_OPTS="-XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -XX:CompileCommand=print,*RuntimeCode.evalStringHelper" ./jperl script.pl
```

Shows actual x86/ARM assembly generated by JIT. Useful for:
- Understanding CPU-level optimizations
- Finding vectorization opportunities
- Analyzing register allocation

---

## Using JPERL_OPTS

The `jperl` launcher script honors the `JPERL_OPTS` environment variable:

```bash
# From jperl script:
java ${JPERL_OPTS} -cp "$CLASSPATH:$JAR_PATH" org.perlonjava.Main "$@"
```

### Common Patterns

```bash
# Multiple flags
JPERL_OPTS="-XX:+PrintCompilation -XX:+PrintGC" ./jperl script.pl

# Disable optimizations for debugging
JPERL_OPTS="-Xint" ./jperl script.pl  # Pure interpreter (no JIT)

# Increase heap size
JPERL_OPTS="-Xmx4g" ./jperl script.pl  # 4GB max heap

# Profile with Java Flight Recorder
JPERL_OPTS="-XX:StartFlightRecording=filename=/tmp/recording.jfr,duration=60s" ./jperl script.pl
```

### Debugging JIT Issues

```bash
# See compilation failures
JPERL_OPTS="-XX:+PrintCompilation -XX:+PrintCompilationFailures" ./jperl script.pl

# Trace deoptimizations
JPERL_OPTS="-XX:+UnlockDiagnosticVMOptions -XX:+TraceDeoptimization" ./jperl script.pl

# Verbose class loading
JPERL_OPTS="-verbose:class" ./jperl script.pl
```

---

## Analysis Techniques

### Identifying Hot Paths

1. **Use PrintCompilation** to see what gets JIT compiled
2. Methods compiled to tier 4 (C2) are the hottest
3. Focus optimization efforts on tier 4 methods

```bash
JPERL_OPTS="-XX:+PrintCompilation" ./jperl script.pl 2>&1 | grep "tier 4"
```

### Finding Allocation Hot Spots

```bash
# Track allocations
JPERL_OPTS="-Xlog:gc*=debug" ./jperl script.pl 2>&1 | grep "allocation"

# Or use JFR
JPERL_OPTS="-XX:StartFlightRecording=settings=profile" ./jperl script.pl
# Analyze with Java Mission Control (jmc)
```

### Measuring Method Overhead

Add timing instrumentation directly in Java code:

```java
public static RuntimeList evalStringWithInterpreter(...) {
    long start = System.nanoTime();

    // ... do work ...

    long elapsed = System.nanoTime() - start;
    if (counter++ % 10000 == 0) {
        System.err.printf("Avg time: %.1f µs\n", elapsed / 1000.0);
    }
}
```

**Important**: Timing inside frequently-called methods can affect JIT optimization. Use sparingly or disable for production.

### Comparing Code Paths

```bash
# Create test workload
cat > /tmp/bench.pl <<'EOF'
for my $x (1..100_000) {
    eval " \$var$x++"
}
EOF

# Time path A
time METHOD_A=1 ./jperl /tmp/bench.pl

# Time path B
time METHOD_B=1 ./jperl /tmp/bench.pl

# Compare results
```

---

## Case Study: EVAL_USE_INTERPRETER Performance

### The Question

Why is compiled code calling interpreter eval 20% slower than pure interpreter mode?

```bash
# Pure interpreter (loop interpreted, eval interpreted)
time ./jperl --interpreter -e 'for (1..5_000_000) { eval "\$var$_++" }'
# Result: 13.45s

# Compiled with interpreter eval (loop compiled, eval interpreted)
time JPERL_EVAL_USE_INTERPRETER=1 ./jperl -e 'for (1..5_000_000) { eval "\$var$_++" }'
# Result: 15.75s (20% slower!)
```

### Initial Hypothesis

BEGIN block aliasing loop runs for every eval, iterating through all captured variables.

### Testing

Reduced iteration count for faster testing:

```bash
# 100K iterations instead of 5M
time ./jperl --interpreter -e 'for (1..100_000) { eval "\$var$_++" }'
# Result: 0.445s (4.45µs per iteration)

time JPERL_EVAL_USE_INTERPRETER=1 ./jperl -e 'for (1..100_000) { eval "\$var$_++" }'
# Result: 0.512s (5.12µs per iteration)

# Overhead: ~0.67µs per eval (15% of eval time)
```

### Investigation

Compared code paths:

**Pure interpreter EVAL_STRING:**
```java
// Already in interpreter, direct access to context
RuntimeScalar result = EvalStringHandler.evalString(
    perlCode,
    code,       // Already have InterpretedCode
    registers,  // Already have registers array
    code.sourceName,
    code.sourceLine
);
```

**Compiled calling interpreter eval:**
```java
// Must reconstruct context from saved EmitterContext
1. Build Object[] array for runtimeValues (allocation + copy)
2. HashMap.get(evalTag) - lookup saved context
3. new EvalRuntimeContext() - object allocation
4. ThreadLocal.set(runtimeCtx) - ThreadLocal overhead
5. ... parse/compile/execute ...
6. ThreadLocal.remove() - cleanup
```

### Root Cause

The overhead comes from:
1. **HashMap lookup** - `evalContext.get(evalTag)` on every eval
2. **Object allocations** - `EvalRuntimeContext` instance
3. **ThreadLocal operations** - `set()` and `remove()` overhead
4. **Array building** - Creating `Object[]` for captured variables
5. **Transition overhead** - JVM bytecode → Java method call

The pure interpreter doesn't need this because it's **already running** with direct access to `code` and `registers`.

### Conclusion

**This overhead is expected and acceptable.**

The tradeoff:
- **Pure interpreter**: Slower loop (interpreted), but zero eval transition overhead
- **Compiled + interpreter eval**: Fast loop (JIT compiled), but ~0.67µs eval transition overhead

The primary benefit of `JPERL_EVAL_USE_INTERPRETER` is **46x faster compilation** for unique eval strings, which far outweighs the small execution overhead.

For workloads with many **unique** eval strings:
```perl
# Before (compile each eval to JVM bytecode): ~14 seconds
for my $x (1..5_000_000) { eval "\$var$x++" }

# After (compile to interpreter bytecode): <1 second
```

The 20% slowdown only matters when:
- Loop is very tight
- Each eval is unique (no caching)
- Execution time dominates compilation time

For most real workloads with complex evals or repeated eval strings, the compilation speedup dominates.

---

## External Profiling Tools

### Java Flight Recorder (JFR)

Built into modern JVMs, low overhead profiling:

```bash
JPERL_OPTS="-XX:StartFlightRecording=filename=/tmp/recording.jfr,duration=60s,settings=profile" ./jperl script.pl

# Analyze with Java Mission Control
jmc /tmp/recording.jfr
```

Shows:
- CPU hotspots
- Allocation hotspots
- GC behavior
- Thread contention
- I/O operations

### async-profiler

Low-overhead CPU and allocation profiler:

```bash
# Download from https://github.com/async-profiler/async-profiler

# CPU profiling
./profiler.sh -d 60 -f /tmp/cpu.html $(pgrep -f "perlonjava")

# Allocation profiling
./profiler.sh -d 60 -e alloc -f /tmp/alloc.html $(pgrep -f "perlonjava")
```

Generates flame graphs showing where time/memory is spent.

### VisualVM

GUI profiler with real-time monitoring:

```bash
# Launch PerlOnJava with debug port
JPERL_OPTS="-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005" ./jperl script.pl

# In another terminal, launch VisualVM
jvisualvm
# Connect to localhost:5005
```

Features:
- CPU sampling
- Memory snapshots
- Thread monitoring
- Heap dumps

### JITWatch

Analyzes JIT compilation logs:

```bash
# Generate log
JPERL_OPTS="-XX:+UnlockDiagnosticVMOptions -XX:+LogCompilation -XX:LogFile=/tmp/jit.xml" ./jperl script.pl

# Launch JITWatch (download from https://github.com/AdoptOpenJDK/jitwatch)
java -jar jitwatch.jar
# Open /tmp/jit.xml
```

Shows:
- Inlining decisions with justifications
- Compilation tiers
- Bytecode and assembly
- Why optimizations failed

---

## Performance Optimization Checklist

When investigating slowness:

1. ✅ **Measure first** - Use `time` to establish baseline
2. ✅ **Identify hot paths** - Use `-XX:+PrintCompilation`
3. ✅ **Check inlining** - Use `-XX:+PrintInlining`
4. ✅ **Profile allocations** - Use `-Xlog:gc*` or JFR
5. ✅ **Compare alternatives** - Time different implementations
6. ✅ **Understand tradeoffs** - Sometimes overhead is acceptable
7. ✅ **Test at scale** - Small tests may not show real bottlenecks

Common pitfalls:
- ❌ Premature optimization based on assumptions
- ❌ Ignoring JIT warmup (first iterations are slower)
- ❌ Optimizing cold paths that don't matter
- ❌ Breaking code readability for negligible gains

---

## Further Reading

- **JVM Options**: https://chriswhocodes.com/
- **Performance Tuning**: "Java Performance: The Definitive Guide" by Scott Oaks
- **JIT Compilation**: https://wiki.openjdk.org/display/HotSpot/
- **Profiling Guide**: https://foojay.io/today/profiling-java-applications/

---

## Contributing

Found better profiling techniques? Add them here! This document should evolve as we learn more about PerlOnJava performance.

Last updated: 2026-02-17
